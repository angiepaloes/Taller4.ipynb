# Taller4.ipynb
taller 4 ana maria paipa y angie paola lopez

**El Dilema del Ajuste: Sobreajuste y Subajuste**

1. Entrenas un modelo y obtienes un 99% de exactitud sobre los datos de entrenamiento, pero solo un 75% sobre los datos de prueba. ¬øQu√© problema indica este resultado y por qu√©?
   **Respuesta**: Este resultado revela un caso de sobreajuste (overfitting). El modelo se ajust√≥  a los datos de entrenamiento, incluso capturando diversos patrones irrelevantes o de ruido, pero no es capaz de desempe√±arse bien con informaci√≥n nueva.
EJP: Es similar a un estudiante que memoriz√≥ las respuestas de la gu√≠a sin comprender realmente los temas. Cuando se enfrenta a preguntas distintas, su desempe√±o disminuye.


2. Si el error de tu modelo es muy alto tanto en el conjunto de entrenamiento como en el de validaci√≥n, ¬øcu√°l es el problema m√°s probable? ¬øCreer√≠as que a√±adir m√°s datos de entrenamiento solucionar√≠a el problema?

   **Respuesta**: Este caso se trata de un subajuste (underfitting). Ya que el modelo es demasiado limitado y no logra aprender todos los patrones reales en los datos.
- En este caso agregar m√°s datos no resolver√≠a el problema porque la dificultad no est√° en la cantidad de informaci√≥n, sino en la capacidad del modelo. Para obtener mejores resultados, ser√≠a necesario usar un modelo m√°s flexible

**El Dilema del Modelo y la Regularizaci√≥n Ridge y Lasso**

1. En un problema para predecir fallas en una m√°quina, tienes 100 variables provenientes de sensores, pero sospechas que solo unas pocas son realmente importantes. ¬øUsar√≠as Ridge o Lasso? Justifica tu respuesta.
   **Respuesta**: Usar√≠a **Lasso** porque Le permite quedarse solo con las variables m√°s √∫tiles y descartar las que no aportan.Si tienes datos de 100 sensores, es probable que varios no sean relevantes o repitan informaci√≥n.por lo que esta metodologia ayuda a simplificar el modelo qued√°ndose solo con los sensores que realmente predicen las fallas con el fin de que el modelo sea m√°s claro.

2. Si entrenas un modelo Lasso y aumentas gradualmente el valor del hiperpar√°metro de penalizaci√≥n (Œª), ¬øqu√© efecto esperar√≠as observar en los coeficientes del modelo?
   **Responder**: Al aumentar el valor de Œª en Lasso, los coeficientes se reducen y varios llegan a cero, lo que hace que el modelo se simplifique y conserve √∫nicamente las variables m√°s relevantes. Por ejemplo, si inicialmente se usan 80 sensores, con un Œª m√°s alto el modelo podr√≠a quedarse solo con alrededor de 10, enfoc√°ndose en los que realmente aportan a predecir las fallas.

3. Al ejecutar el c√≥digo de regularizaci√≥n 3D, ¬øqu√© sucede con los coeficientes del modelo a medida que aumenta el valor de Œª? ¬øQu√© interpretaci√≥n le das a la forma diferente en que Ridge y Lasso aplican sus penalizaciones?
**Respuesta**: Ridge reduce los coeficientes sin eliminarlos, por lo que todas las variables siguen en el modelo, solo con menor peso. Es √∫til cuando todas aportan algo o hay variables muy correlacionadas.
En cambio, Lasso puede llevar algunos coeficientes a cero, eliminando variables y haciendo una selecci√≥n autom√°tica. Sirve cuando hay muchas variables redundantes o poco √∫tiles.

GridSearchCV: Encontrando la Mejor Configuraci√≥n para tu Modelo üîé

1. Quieres optimizar un modelo Ridge y pruebas manualmente alpha=10, obteniendo un buen resultado. ¬øPor qu√© sigue siendo metodol√≥gicamente superior usar GridSearchCV en lugar de quedarte con ese valor?
respuesta:Aunque probar manualmente un valor como alpha=10 puede dar buenos resultados, no es lo m√°s riguroso. Usar GridSearchCV es mejor porque eval√∫a de forma sistem√°tica varios valores y valida el desempe√±o del modelo con cross-validation. Esto evita que el par√°metro elegido funcione solo por casualidad en un conjunto de datos espec√≠fico y garantiza una mejor capacidad de generalizaci√≥n.


2. Adem√°s del modelo en s√≠ (ej. Lasso()), ¬øcu√°les son los dos componentes principales que debes proporcionar a GridSearchCV para iniciar la b√∫squeda de hiperpar√°metros?
Respuesta: Debes proporcionarle:

‚úÖ El diccionario de hiperpar√°metros a explorar (param_grid).

‚úÖ La estrategia de validaci√≥n cruzada (por ejemplo, cv=5 o cv=10).

Con eso puede empezar la b√∫squeda.

3. Si GridSearchCV selecciona un alpha muy peque√±o (cercano a cero) como el mejor par√°metro para tu modelo, ¬øqu√© te sugiere esto sobre el nivel de sobreajuste que ten√≠a tu modelo original sin regularizar?
respuesta: Si GridSearchCV elige un alpha muy peque√±o, indica que el modelo inicial no ten√≠a un sobreajuste significativo. Esto quiere decir que no hac√≠a falta aplicar una regularizaci√≥n fuerte, porque el modelo sin penalizaci√≥n ya estaba bien equilibrado. En resumen, el ajuste original era adecuado y solo necesitaba una correcci√≥n leve.

Construir un √Årbol de Decisi√≥n: El Diagrama de Flujo Inteligente para la Optimizaci√≥n de Procesos üè≠

1. En un √°rbol de decisi√≥n para optimizar la log√≠stica de un almac√©n, ¬øqu√© podr√≠a representar un nodo hoja?
   respuesta: Un nodo hoja es el resultado final al que llega el √°rbol despu√©s de evaluar todas las condiciones. En un almac√©n, este nodo puede representar una acci√≥n log√≠stica (como asignar el pedido a despacho r√°pido), una categor√≠a de decisi√≥n (alta o baja prioridad) o un valor espec√≠fico (por ejemplo, tiempo de entrega o costo). En pocas palabras, es la predicci√≥n o decisi√≥n concreta que produce el modelo.

3. Un ingeniero crea un √°rbol para predecir fallos en una m√°quina. El √°rbol es extremadamente profundo y tiene reglas muy espec√≠ficas como "Si la temperatura es 75.3¬∞C y la vibraci√≥n es 0.152 m/s¬≤ y el operador es Juan...". ¬øQu√© problema de ajuste es este y por qu√© no ser√≠a fiable en la pr√°ctica diaria de la planta?
respuesta : Ese es un caso de sobreajuste. El √°rbol se volvi√≥ tan espec√≠fico que empez√≥ a memorizar detalles irrelevantes, como valores exactos o condiciones muy puntuales. En la pr√°ctica no funciona bien porque las condiciones cambian ligeramente y el modelo no generaliza, solo repite lo que vio. Por eso puede tener buen desempe√±o con los datos hist√≥ricos, pero fallar cuando se enfrenta a nuevas situaciones reales.

Evaluando el Diagn√≥stico: La Matriz de Confusi√≥n y el F1-Score üî¨

1. Al visualizar la "importancia de las caracter√≠sticas" de tu √°rbol, descubres que el "proveedor de materia prima" es la variable m√°s importante. ¬øQu√© acci√≥n inmediata podr√≠as tomar en la planta con esta informaci√≥n?
Respuesta: Si el modelo muestra que el proveedor es la variable m√°s influyente, lo primero ser√≠a analizar el desempe√±o de cada uno: revisar tasas de defectos, tiempos de entrega y costos. Esto permite detectar si alg√∫n proveedor est√° generando m√°s problemas. Con esa informaci√≥n se pueden tomar acciones como renegociar, aplicar controles m√°s estrictos o reemplazarlo. En resumen, el √°rbol permite concentrarse en el factor que m√°s afecta el desempe√±o de la planta.


3. Si tu √°rbol de decisi√≥n est√° clasificando perfectamente los datos hist√≥ricos pero falla mucho con los datos de la √∫ltima semana (sobreajuste), ¬øqu√© par√°metro de poda ajustar√≠as primero para que generalice mejor?
respuesta: El primer par√°metro a ajustar ser√≠a max_depth, ya que limitar la profundidad del √°rbol evita que aprenda reglas demasiado espec√≠ficas y lo obliga a enfocarse en patrones m√°s generales. Tambi√©n se pueden usar par√°metros como min_samples_split o min_samples_leaf, que controlan cu√°ntos datos se necesitan para dividir un nodo o crear una hoja. En resumen, reducir la profundidad es la forma m√°s efectiva de prevenir el sobreajuste en √°rboles de decisi√≥n.



